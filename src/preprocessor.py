"""
ì§€í•˜ì²  í˜¼ì¡ë„ ì˜ˆì¸¡ - ë°ì´í„° ì „ì²˜ë¦¬ ëª¨ë“ˆ
subway-congestion-prediction/src/preprocessor.py

ì£¼ìš” ê¸°ëŠ¥:
1. ì™€ì´ë“œ í¬ë§· â†’ ë¡± í¬ë§· ë³€í™˜
2. ë‚ ì§œ/ì‹œê°„ ë°ì´í„° ì²˜ë¦¬
3. ê²°ì¸¡ì¹˜ ì²˜ë¦¬
4. ì´ìƒì¹˜ íƒì§€ ë° ì²˜ë¦¬
5. ë°ì´í„° ì •ê·œí™”
"""

import pandas as pd
import numpy as np
from datetime import datetime
import os
import warnings
warnings.filterwarnings('ignore')


class SubwayDataPreprocessor:
    """ì§€í•˜ì²  ìŠ¹í•˜ì°¨ ë°ì´í„° ì „ì²˜ë¦¬ í´ë˜ìŠ¤"""
    
    def __init__(self, raw_data_path, processed_data_path):
        """
        Args:
            raw_data_path: ì›ë³¸ ë°ì´í„° ê²½ë¡œ (data/raw/)
            processed_data_path: ì „ì²˜ë¦¬ëœ ë°ì´í„° ì €ì¥ ê²½ë¡œ (data/processed/)
        """
        self.raw_data_path = raw_data_path
        self.processed_data_path = processed_data_path
        
        # í´ë”ê°€ ì—†ìœ¼ë©´ ìƒì„±
        os.makedirs(processed_data_path, exist_ok=True)
        
        self.df = None
        self.df_long = None
        
    def load_data(self, filename='subway_20250101_20251101.csv'):
        """ì›ë³¸ ë°ì´í„° ë¡œë“œ"""
        filepath = os.path.join(self.raw_data_path, filename)
        
        print(f"ğŸ“‚ ë°ì´í„° ë¡œë”© ì¤‘: {filepath}")
        self.df = pd.read_csv(filepath, encoding='utf-8-sig')
        
        print(f"âœ… ë¡œë”© ì™„ë£Œ!")
        print(f"   - í–‰ ìˆ˜: {len(self.df):,}")
        print(f"   - ì—´ ìˆ˜: {len(self.df.columns)}")
        print(f"   - ë©”ëª¨ë¦¬: {self.df.memory_usage(deep=True).sum() / 1024**2:.2f} MB")
        
        return self.df
    
    def check_data_quality(self):
        """ë°ì´í„° í’ˆì§ˆ ì²´í¬"""
        print("\nğŸ” ë°ì´í„° í’ˆì§ˆ ì²´í¬")
        print("=" * 60)
        
        # ì‹¤ì œ ì»¬ëŸ¼ëª… ì¶œë ¥
        print("\nğŸ“‹ ì‹¤ì œ ì»¬ëŸ¼ëª…:")
        print(self.df.columns.tolist())
        
        # 1. ê²°ì¸¡ì¹˜ í™•ì¸
        missing = self.df.isnull().sum()
        if missing.sum() > 0:
            print("\nâš ï¸  ê²°ì¸¡ì¹˜ ë°œê²¬:")
            print(missing[missing > 0])
        else:
            print("âœ… ê²°ì¸¡ì¹˜ ì—†ìŒ")
        
        # ì»¬ëŸ¼ëª…ì´ ì‹¤ì œë¡œ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
        required_cols = []
        for col in self.df.columns:
            if 'ì¼ì' in col or 'ë‚ ì§œ' in col or 'ì‚¬ìš©ì¼' in col:
                date_col = col
                required_cols.append(col)
            elif 'ë…¸ì„ ' in col or 'í˜¸ì„ ' in col:
                line_col = col
                required_cols.append(col)
            elif 'ì—­ëª…' in col or 'ì—­' in col:
                station_col = col
                required_cols.append(col)
        
        # 2. ì¤‘ë³µ ë°ì´í„° í™•ì¸ (ì»¬ëŸ¼ì´ ì¡´ì¬í•˜ëŠ” ê²½ìš°ë§Œ)
        if len(required_cols) >= 3:
            duplicates = self.df.duplicated(subset=required_cols).sum()
            print(f"\nì¤‘ë³µ í–‰: {duplicates}ê°œ")
        
        # 3. ë‚ ì§œ ì»¬ëŸ¼ ì°¾ê¸° ë° ë³€í™˜
        date_column = None
        for col in self.df.columns:
            if 'ì¼ì' in col or 'ë‚ ì§œ' in col or 'ì‚¬ìš©ì¼' in col:
                date_column = col
                break
        
        if date_column:
            # ë‚ ì§œ í˜•ì‹ ìë™ ê°ì§€ ë° ë³€í™˜
            try:
                self.df[date_column] = pd.to_datetime(self.df[date_column], format='%Y%m%d')
            except:
                try:
                    self.df[date_column] = pd.to_datetime(self.df[date_column])
                except:
                    print(f"âš ï¸  ë‚ ì§œ ë³€í™˜ ì‹¤íŒ¨: {date_column}")
            
            print(f"\në‚ ì§œ ë²”ìœ„: {self.df[date_column].min()} ~ {self.df[date_column].max()}")
        
        # 4. ë…¸ì„  ë° ì—­ ê°œìˆ˜ (ì»¬ëŸ¼ì´ ì¡´ì¬í•˜ëŠ” ê²½ìš°ë§Œ)
        for col in self.df.columns:
            if 'ë…¸ì„ ' in col or 'í˜¸ì„ ' in col:
                print(f"\në…¸ì„  ìˆ˜: {self.df[col].nunique()}ê°œ")
            if 'ì—­ëª…' in col or 'ì—­' in col:
                print(f"ì—­ ìˆ˜: {self.df[col].nunique()}ê°œ")
        
        return self.df
    
    def wide_to_long(self):
        """ì™€ì´ë“œ í¬ë§· â†’ ë¡± í¬ë§· ë³€í™˜"""
        print("\nğŸ”„ ë°ì´í„° í˜•íƒœ ë³€í™˜ ì¤‘ (Wide â†’ Long)")
        
        # ì‹œê°„ëŒ€ ì»¬ëŸ¼ ì¶”ì¶œ
        time_columns = [col for col in self.df.columns if 'ì‹œ-' in col]
        
        print(f"   - ì‹œê°„ëŒ€ ì»¬ëŸ¼ ìˆ˜: {len(time_columns)}ê°œ")
        
        # ë¡± í¬ë§·ìœ¼ë¡œ ë³€í™˜
        self.df_long = pd.melt(
            self.df,
            id_vars=['USE_YMD', 'USE_YMD', 'SBWY_STNS_NM'],
            value_vars=time_columns,
            var_name='ì‹œê°„ëŒ€',
            value_name='ìŠ¹í•˜ì°¨ì¸ì›'
        )
        
        # ì‹œê°„ëŒ€ ì •ë¦¬ (05ì‹œ-06ì‹œ â†’ 05)
        self.df_long['ì‹œê°„'] = self.df_long['ì‹œê°„ëŒ€'].str.extract(r'(\d+)ì‹œ').astype(int)
        
        # ë¶ˆí•„ìš”í•œ ì»¬ëŸ¼ ì œê±°
        self.df_long = self.df_long.drop('ì‹œê°„ëŒ€', axis=1)
        
        print(f"âœ… ë³€í™˜ ì™„ë£Œ!")
        print(f"   - ë³€í™˜ í›„ í–‰ ìˆ˜: {len(self.df_long):,}")
        
        return self.df_long
    
    def add_time_features(self):
        """ë‚ ì§œ/ì‹œê°„ ê´€ë ¨ í”¼ì²˜ ì¶”ê°€"""
        print("\nğŸ“… ì‹œê°„ í”¼ì²˜ ìƒì„± ì¤‘...")
        
        # ë‚ ì§œ ì •ë³´ ì¶”ì¶œ
        self.df_long['ì—°ë„'] = self.df_long['ì‚¬ìš©ì¼ì'].dt.year
        self.df_long['ì›”'] = self.df_long['ì‚¬ìš©ì¼ì'].dt.month
        self.df_long['ì¼'] = self.df_long['ì‚¬ìš©ì¼ì'].dt.day
        self.df_long['ìš”ì¼'] = self.df_long['ì‚¬ìš©ì¼ì'].dt.dayofweek
        self.df_long['ìš”ì¼ëª…'] = self.df_long['ì‚¬ìš©ì¼ì'].dt.day_name()
        
        # ì£¼ì¤‘/ì£¼ë§ êµ¬ë¶„
        self.df_long['ì£¼ë§ì—¬ë¶€'] = self.df_long['ìš”ì¼'].apply(lambda x: 1 if x >= 5 else 0)
        
        # ì¶œí‡´ê·¼ ì‹œê°„ëŒ€ êµ¬ë¶„
        def classify_time_period(hour):
            if 7 <= hour <= 9:
                return 'ì¶œê·¼ì‹œê°„'
            elif 18 <= hour <= 20:
                return 'í‡´ê·¼ì‹œê°„'
            elif 11 <= hour <= 13:
                return 'ì ì‹¬ì‹œê°„'
            elif 22 <= hour or hour <= 5:
                return 'ì‹¬ì•¼ì‹œê°„'
            else:
                return 'ì¼ë°˜ì‹œê°„'
        
        self.df_long['ì‹œê°„ëŒ€êµ¬ë¶„'] = self.df_long['ì‹œê°„'].apply(classify_time_period)
        
        print("âœ… ì‹œê°„ í”¼ì²˜ ì¶”ê°€ ì™„ë£Œ!")
        
        return self.df_long
    
    def handle_outliers(self, method='iqr'):
        """ì´ìƒì¹˜ ì²˜ë¦¬"""
        print(f"\nğŸ”§ ì´ìƒì¹˜ ì²˜ë¦¬ ì¤‘...")
        
        Q1 = self.df_long['ìŠ¹í•˜ì°¨ì¸ì›'].quantile(0.25)
        Q3 = self.df_long['ìŠ¹í•˜ì°¨ì¸ì›'].quantile(0.75)
        IQR = Q3 - Q1
        
        upper_bound = Q3 + 1.5 * IQR
        
        # ìŒìˆ˜ ê°’ì€ 0ìœ¼ë¡œ ì²˜ë¦¬
        self.df_long['ìŠ¹í•˜ì°¨ì¸ì›'] = self.df_long['ìŠ¹í•˜ì°¨ì¸ì›'].clip(lower=0)
        
        # ì´ìƒì¹˜ëŠ” ìƒí•œê°’ìœ¼ë¡œ ëŒ€ì²´
        outliers = (self.df_long['ìŠ¹í•˜ì°¨ì¸ì›'] > upper_bound * 2)
        outlier_count = outliers.sum()
        self.df_long.loc[outliers, 'ìŠ¹í•˜ì°¨ì¸ì›'] = upper_bound
        
        print(f"âœ… ì´ìƒì¹˜ ì²˜ë¦¬ ì™„ë£Œ! ì²˜ë¦¬ëœ ì´ìƒì¹˜: {outlier_count:,}ê°œ")
        
        return self.df_long
    
    def add_station_statistics(self):
        """ì—­ë³„ í†µê³„ ì •ë³´ ì¶”ê°€"""
        print("\nğŸ“Š ì—­ë³„ í†µê³„ ìƒì„± ì¤‘...")
        
        # ì—­ë³„ í‰ê·  ìŠ¹í•˜ì°¨ ì¸ì›
        station_avg = self.df_long.groupby('ì—­ëª…')['ìŠ¹í•˜ì°¨ì¸ì›'].mean().reset_index()
        station_avg.columns = ['ì—­ëª…', 'ì—­_í‰ê· ìŠ¹í•˜ì°¨']
        
        # ì‹œê°„ëŒ€ë³„ í‰ê·  ìŠ¹í•˜ì°¨ ì¸ì›
        time_avg = self.df_long.groupby('ì‹œê°„')['ìŠ¹í•˜ì°¨ì¸ì›'].mean().reset_index()
        time_avg.columns = ['ì‹œê°„', 'ì‹œê°„_í‰ê· ìŠ¹í•˜ì°¨']
        
        # ì›ë³¸ ë°ì´í„°ì— ë³‘í•©
        self.df_long = self.df_long.merge(station_avg, on='ì—­ëª…', how='left')
        self.df_long = self.df_long.merge(time_avg, on='ì‹œê°„', how='left')
        
        print("âœ… ì—­ë³„ í†µê³„ ì¶”ê°€ ì™„ë£Œ!")
        
        return self.df_long
    
    def normalize_station_names(self):
        """ì—­ëª… í‘œì¤€í™”"""
        print("\nğŸ”¤ ì—­ëª… í‘œì¤€í™” ì¤‘...")
        
        self.df_long['ì—­ëª…'] = self.df_long['ì—­ëª…'].str.strip()
        self.df_long['ë…¸ì„ ëª…'] = self.df_long['ë…¸ì„ ëª…'].str.strip()
        
        print(f"âœ… í‘œì¤€í™” ì™„ë£Œ!")
        
        return self.df_long
    
    def save_processed_data(self, filename='subway_processed.csv'):
        """ì „ì²˜ë¦¬ëœ ë°ì´í„° ì €ì¥"""
        filepath = os.path.join(self.processed_data_path, filename)
        
        print(f"\nğŸ’¾ ì „ì²˜ë¦¬ ë°ì´í„° ì €ì¥ ì¤‘: {filepath}")
        
        self.df_long.to_csv(filepath, index=False, encoding='utf-8-sig')
        
        print(f"âœ… ì €ì¥ ì™„ë£Œ!")
        print(f"   - ìµœì¢… í–‰ ìˆ˜: {len(self.df_long):,}")
        print(f"   - íŒŒì¼ í¬ê¸°: {os.path.getsize(filepath) / 1024**2:.2f} MB")
        
        return filepath
    
    def get_summary(self):
        """ì „ì²˜ë¦¬ ê²°ê³¼ ìš”ì•½"""
        print("\n" + "="*60)
        print("ğŸ“‹ ì „ì²˜ë¦¬ ê²°ê³¼ ìš”ì•½")
        print("="*60)
        
        print(f"\nì´ ë°ì´í„° ìˆ˜: {len(self.df_long):,}ê°œ")
        print(f"ê¸°ê°„: {self.df_long['ì‚¬ìš©ì¼ì'].min()} ~ {self.df_long['ì‚¬ìš©ì¼ì'].max()}")
        print(f"ë…¸ì„  ìˆ˜: {self.df_long['ë…¸ì„ ëª…'].nunique()}ê°œ")
        print(f"ì—­ ìˆ˜: {self.df_long['ì—­ëª…'].nunique()}ê°œ")
        
        print("\nìŠ¹í•˜ì°¨ ì¸ì› í†µê³„:")
        print(self.df_long['ìŠ¹í•˜ì°¨ì¸ì›'].describe())
        
        print("\nì‹œê°„ëŒ€êµ¬ë¶„ë³„ í‰ê·  ìŠ¹í•˜ì°¨:")
        print(self.df_long.groupby('ì‹œê°„ëŒ€êµ¬ë¶„')['ìŠ¹í•˜ì°¨ì¸ì›'].mean().sort_values(ascending=False))


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    
    print("ğŸš‡ ì§€í•˜ì²  í˜¼ì¡ë„ ì˜ˆì¸¡ - ë°ì´í„° ì „ì²˜ë¦¬ ì‹œì‘")
    print("="*60)
    
    # ê²½ë¡œ ì„¤ì •
    RAW_DATA_PATH = 'data/raw/subway'
    PROCESSED_DATA_PATH = 'data/processed'
    
    # ì „ì²˜ë¦¬ ê°ì²´ ìƒì„±
    preprocessor = SubwayDataPreprocessor(RAW_DATA_PATH, PROCESSED_DATA_PATH)
    
    # 1. ë°ì´í„° ë¡œë“œ
    preprocessor.load_data()
    
    # 2. ë°ì´í„° í’ˆì§ˆ ì²´í¬
    preprocessor.check_data_quality()
    
    # 3. ì™€ì´ë“œ â†’ ë¡± í¬ë§· ë³€í™˜
    preprocessor.wide_to_long()
    
    # 4. ì‹œê°„ í”¼ì²˜ ì¶”ê°€
    preprocessor.add_time_features()
    
    # 5. ì—­ëª… í‘œì¤€í™”
    preprocessor.normalize_station_names()
    
    # 6. ì´ìƒì¹˜ ì²˜ë¦¬
    preprocessor.handle_outliers()
    
    # 7. ì—­ë³„ í†µê³„ ì¶”ê°€
    preprocessor.add_station_statistics()
    
    # 8. ì €ì¥
    preprocessor.save_processed_data()
    
    # 9. ìš”ì•½
    preprocessor.get_summary()
    
    print("\nâœ… ì „ì²˜ë¦¬ ì™„ë£Œ!")


if __name__ == '__main__':
    main()