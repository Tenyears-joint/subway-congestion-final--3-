"""
ì§€í•˜ì²  í˜¼ì¡ë„ ì˜ˆì¸¡ - FastAPI ë°±ì—”ë“œ (ê°•í™”ëœ í”¼ì²˜ ë²„ì „)
"""

from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel, Field
from typing import List, Optional, Dict
import pandas as pd
import pickle
import numpy as np
from datetime import datetime
import os

# FastAPI ì•± ìƒì„±
app = FastAPI(
    title="ì§€í•˜ì²  í˜¼ì¡ë„ ì˜ˆì¸¡ API",
    description="ì„œìš¸ ì§€í•˜ì²  í˜¼ì¡ë„ë¥¼ ì˜ˆì¸¡í•˜ëŠ” API (ê°•í™”ëœ í”¼ì²˜ ë²„ì „)",
    version="1.0.0"
)

# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ì „ì—­ ë³€ìˆ˜
model = None
feature_names = None
df_stations = None
df_features = None

# ì—­ ì¹´í…Œê³ ë¦¬ ì •ì˜
STATION_CATEGORIES = {
    # ì´ˆëŒ€í˜• ì—…ë¬´ + ìƒì—… ì§€êµ¬
    'ê°•ë‚¨': {'ì—…ë¬´ì§€êµ¬': 1, 'ìƒì—…ì§€êµ¬': 1, 'í™˜ìŠ¹ì—­ë“±ê¸‰': 2, 'ëŒ€í•™ê°€': 0, 'ì£¼ê±°ì§€ì—­': 0, 'ì—­_ê·¸ë£¹': 1},
    'ì—­ì‚¼': {'ì—…ë¬´ì§€êµ¬': 1, 'ìƒì—…ì§€êµ¬': 1, 'í™˜ìŠ¹ì—­ë“±ê¸‰': 0, 'ëŒ€í•™ê°€': 0, 'ì£¼ê±°ì§€ì—­': 0, 'ì—­_ê·¸ë£¹': 1},
    'ì„ ë¦‰': {'ì—…ë¬´ì§€êµ¬': 1, 'ìƒì—…ì§€êµ¬': 0, 'í™˜ìŠ¹ì—­ë“±ê¸‰': 1, 'ëŒ€í•™ê°€': 0, 'ì£¼ê±°ì§€ì—­': 0, 'ì—­_ê·¸ë£¹': 1},
    'ì‚¼ì„±': {'ì—…ë¬´ì§€êµ¬': 1, 'ìƒì—…ì§€êµ¬': 1, 'í™˜ìŠ¹ì—­ë“±ê¸‰': 0, 'ëŒ€í•™ê°€': 0, 'ì£¼ê±°ì§€ì—­': 0, 'ì—­_ê·¸ë£¹': 1},
    'ì—¬ì˜ë„': {'ì—…ë¬´ì§€êµ¬': 1, 'ìƒì—…ì§€êµ¬': 0, 'í™˜ìŠ¹ì—­ë“±ê¸‰': 2, 'ëŒ€í•™ê°€': 0, 'ì£¼ê±°ì§€ì—­': 0, 'ì—­_ê·¸ë£¹': 1},
    'ê´‘í™”ë¬¸': {'ì—…ë¬´ì§€êµ¬': 1, 'ìƒì—…ì§€êµ¬': 1, 'í™˜ìŠ¹ì—­ë“±ê¸‰': 0, 'ëŒ€í•™ê°€': 0, 'ì£¼ê±°ì§€ì—­': 0, 'ì—­_ê·¸ë£¹': 1},
    'ì¢…ê°': {'ì—…ë¬´ì§€êµ¬': 1, 'ìƒì—…ì§€êµ¬': 1, 'í™˜ìŠ¹ì—­ë“±ê¸‰': 1, 'ëŒ€í•™ê°€': 0, 'ì£¼ê±°ì§€ì—­': 0, 'ì—­_ê·¸ë£¹': 1},
    
    # ìƒì—…/ì‡¼í•‘ ì§€êµ¬
    'í™ëŒ€ì…êµ¬': {'ì—…ë¬´ì§€êµ¬': 0, 'ìƒì—…ì§€êµ¬': 1, 'í™˜ìŠ¹ì—­ë“±ê¸‰': 2, 'ëŒ€í•™ê°€': 1, 'ì£¼ê±°ì§€ì—­': 0, 'ì—­_ê·¸ë£¹': 2},
    'ì‹ ì´Œ': {'ì—…ë¬´ì§€êµ¬': 0, 'ìƒì—…ì§€êµ¬': 1, 'í™˜ìŠ¹ì—­ë“±ê¸‰': 0, 'ëŒ€í•™ê°€': 1, 'ì£¼ê±°ì§€ì—­': 0, 'ì—­_ê·¸ë£¹': 2},
    'ëª…ë™': {'ì—…ë¬´ì§€êµ¬': 0, 'ìƒì—…ì§€êµ¬': 1, 'í™˜ìŠ¹ì—­ë“±ê¸‰': 0, 'ëŒ€í•™ê°€': 0, 'ì£¼ê±°ì§€ì—­': 0, 'ì—­_ê·¸ë£¹': 2},
    'ë™ëŒ€ë¬¸': {'ì—…ë¬´ì§€êµ¬': 0, 'ìƒì—…ì§€êµ¬': 1, 'í™˜ìŠ¹ì—­ë“±ê¸‰': 2, 'ëŒ€í•™ê°€': 0, 'ì£¼ê±°ì§€ì—­': 0, 'ì—­_ê·¸ë£¹': 2},
    'ì„ì§€ë¡œì…êµ¬': {'ì—…ë¬´ì§€êµ¬': 1, 'ìƒì—…ì§€êµ¬': 1, 'í™˜ìŠ¹ì—­ë“±ê¸‰': 1, 'ëŒ€í•™ê°€': 0, 'ì£¼ê±°ì§€ì—­': 0, 'ì—­_ê·¸ë£¹': 1},
    
    # ëŒ€í•™ê°€
    'ì‹ ë¦¼': {'ì—…ë¬´ì§€êµ¬': 0, 'ìƒì—…ì§€êµ¬': 0, 'í™˜ìŠ¹ì—­ë“±ê¸‰': 0, 'ëŒ€í•™ê°€': 1, 'ì£¼ê±°ì§€ì—­': 1, 'ì—­_ê·¸ë£¹': 3},
    'ì„œìš¸ëŒ€ì…êµ¬': {'ì—…ë¬´ì§€êµ¬': 0, 'ìƒì—…ì§€êµ¬': 0, 'í™˜ìŠ¹ì—­ë“±ê¸‰': 0, 'ëŒ€í•™ê°€': 1, 'ì£¼ê±°ì§€ì—­': 0, 'ì—­_ê·¸ë£¹': 3},
    'ì´ëŒ€': {'ì—…ë¬´ì§€êµ¬': 0, 'ìƒì—…ì§€êµ¬': 1, 'í™˜ìŠ¹ì—­ë“±ê¸‰': 0, 'ëŒ€í•™ê°€': 1, 'ì£¼ê±°ì§€ì—­': 0, 'ì—­_ê·¸ë£¹': 3},
    'ê±´ëŒ€ì…êµ¬': {'ì—…ë¬´ì§€êµ¬': 0, 'ìƒì—…ì§€êµ¬': 1, 'í™˜ìŠ¹ì—­ë“±ê¸‰': 1, 'ëŒ€í•™ê°€': 1, 'ì£¼ê±°ì§€ì—­': 0, 'ì—­_ê·¸ë£¹': 3},
    
    # ì´ˆëŒ€í˜• í™˜ìŠ¹ì—­
    'ì™•ì‹­ë¦¬': {'ì—…ë¬´ì§€êµ¬': 0, 'ìƒì—…ì§€êµ¬': 0, 'í™˜ìŠ¹ì—­ë“±ê¸‰': 4, 'ëŒ€í•™ê°€': 0, 'ì£¼ê±°ì§€ì—­': 0, 'ì—­_ê·¸ë£¹': 4},
    'ì‹ ë„ë¦¼': {'ì—…ë¬´ì§€êµ¬': 0, 'ìƒì—…ì§€êµ¬': 1, 'í™˜ìŠ¹ì—­ë“±ê¸‰': 3, 'ëŒ€í•™ê°€': 0, 'ì£¼ê±°ì§€ì—­': 0, 'ì—­_ê·¸ë£¹': 4},
    'ì‚¬ë‹¹': {'ì—…ë¬´ì§€êµ¬': 0, 'ìƒì—…ì§€êµ¬': 0, 'í™˜ìŠ¹ì—­ë“±ê¸‰': 3, 'ëŒ€í•™ê°€': 0, 'ì£¼ê±°ì§€ì—­': 1, 'ì—­_ê·¸ë£¹': 4},
    'ì ì‹¤': {'ì—…ë¬´ì§€êµ¬': 0, 'ìƒì—…ì§€êµ¬': 1, 'í™˜ìŠ¹ì—­ë“±ê¸‰': 2, 'ëŒ€í•™ê°€': 0, 'ì£¼ê±°ì§€ì—­': 1, 'ì—­_ê·¸ë£¹': 4},
    'êµëŒ€': {'ì—…ë¬´ì§€êµ¬': 0, 'ìƒì—…ì§€êµ¬': 0, 'í™˜ìŠ¹ì—­ë“±ê¸‰': 2, 'ëŒ€í•™ê°€': 0, 'ì£¼ê±°ì§€ì—­': 0, 'ì—­_ê·¸ë£¹': 4},
    'ê³ ì†í„°ë¯¸ë„': {'ì—…ë¬´ì§€êµ¬': 0, 'ìƒì—…ì§€êµ¬': 1, 'í™˜ìŠ¹ì—­ë“±ê¸‰': 3, 'ëŒ€í•™ê°€': 0, 'ì£¼ê±°ì§€ì—­': 0, 'ì—­_ê·¸ë£¹': 4},
    
    # ì£¼ê±° ì§€ì—­
    'ëª©ë™': {'ì—…ë¬´ì§€êµ¬': 0, 'ìƒì—…ì§€êµ¬': 0, 'í™˜ìŠ¹ì—­ë“±ê¸‰': 0, 'ëŒ€í•™ê°€': 0, 'ì£¼ê±°ì§€ì—­': 1, 'ì—­_ê·¸ë£¹': 5},
    'ë…¸ì›': {'ì—…ë¬´ì§€êµ¬': 0, 'ìƒì—…ì§€êµ¬': 0, 'í™˜ìŠ¹ì—­ë“±ê¸‰': 2, 'ëŒ€í•™ê°€': 0, 'ì£¼ê±°ì§€ì—­': 1, 'ì—­_ê·¸ë£¹': 5},
    'ìˆ˜ìœ ': {'ì—…ë¬´ì§€êµ¬': 0, 'ìƒì—…ì§€êµ¬': 0, 'í™˜ìŠ¹ì—­ë“±ê¸‰': 0, 'ëŒ€í•™ê°€': 0, 'ì£¼ê±°ì§€ì—­': 1, 'ì—­_ê·¸ë£¹': 5},
    'êµ¬ë¡œë””ì§€í„¸ë‹¨ì§€': {'ì—…ë¬´ì§€êµ¬': 1, 'ìƒì—…ì§€êµ¬': 0, 'í™˜ìŠ¹ì—­ë“±ê¸‰': 1, 'ëŒ€í•™ê°€': 0, 'ì£¼ê±°ì§€ì—­': 0, 'ì—­_ê·¸ë£¹': 1},
    
    # ì™¸ê³½ ì§€ì—­
    'ê¹Œì¹˜ì‚°': {'ì—…ë¬´ì§€êµ¬': 0, 'ìƒì—…ì§€êµ¬': 0, 'í™˜ìŠ¹ì—­ë“±ê¸‰': 0, 'ëŒ€í•™ê°€': 0, 'ì£¼ê±°ì§€ì—­': 1, 'ì—­_ê·¸ë£¹': 6},
    'ì‹ ì •ë„¤ê±°ë¦¬': {'ì—…ë¬´ì§€êµ¬': 0, 'ìƒì—…ì§€êµ¬': 0, 'í™˜ìŠ¹ì—­ë“±ê¸‰': 0, 'ëŒ€í•™ê°€': 0, 'ì£¼ê±°ì§€ì—­': 1, 'ì—­_ê·¸ë£¹': 6},
}

# ê¸°ë³¸ê°’
DEFAULT_CATEGORY = {'ì—…ë¬´ì§€êµ¬': 0, 'ìƒì—…ì§€êµ¬': 0, 'í™˜ìŠ¹ì—­ë“±ê¸‰': 0, 'ëŒ€í•™ê°€': 0, 'ì£¼ê±°ì§€ì—­': 0, 'ì—­_ê·¸ë£¹': 0}

# í˜¼ì¡ë„ ë ˆë²¨ ë§¤í•‘
CONGESTION_LEVEL_MAP = {
    0: "ì—¬ìœ ",
    1: "ë³´í†µ",
    2: "í˜¼ì¡",
    3: "ë§¤ìš°í˜¼ì¡"
}

CONGESTION_COLOR_MAP = {
    0: "#4CAF50",
    1: "#FFC107",
    2: "#FF9800",
    3: "#F44336"
}

# ìš”ì¼ í•œê¸€ ë§¤í•‘
DAY_NAME_MAP = {
    0: "ì›”ìš”ì¼",
    1: "í™”ìš”ì¼",
    2: "ìˆ˜ìš”ì¼",
    3: "ëª©ìš”ì¼",
    4: "ê¸ˆìš”ì¼",
    5: "í† ìš”ì¼",
    6: "ì¼ìš”ì¼"
}


# ============================================
# Pydantic ëª¨ë¸ ì •ì˜
# ============================================

class PredictionRequest(BaseModel):
    station_name: str = Field(..., description="ì§€í•˜ì² ì—­ ì´ë¦„")
    line_name: str = Field(..., description="í˜¸ì„ ëª…")
    hour: int = Field(..., ge=0, le=23, description="ì‹œê°„ (0-23)")
    day_of_week: int = Field(..., ge=0, le=6, description="ìš”ì¼ (0=ì›”, 6=ì¼)")
    month: Optional[int] = Field(None, ge=1, le=12, description="ì›”")
    is_holiday: Optional[bool] = Field(False, description="ê³µíœ´ì¼ ì—¬ë¶€")


class PredictionResponse(BaseModel):
    success: bool
    prediction: Dict
    input: Dict
    recommendation: str
    timestamp: str


class StationInfo(BaseModel):
    name: str
    line: str
    is_transfer: Optional[bool] = False


# ============================================
# ëª¨ë¸ ë° ë°ì´í„° ë¡œë“œ
# ============================================

@app.on_event("startup")
async def load_model():
    """ì„œë²„ ì‹œì‘ ì‹œ ëª¨ë¸ ë° ë°ì´í„° ë¡œë“œ"""
    global model, feature_names, df_stations, df_features
    
    print("="*80)
    print("ğŸš‡ ì§€í•˜ì²  í˜¼ì¡ë„ ì˜ˆì¸¡ API ì„œë²„ ì‹œì‘")
    print("="*80)
    
    try:
        # 1. ëª¨ë¸ ë¡œë“œ
        model_path = 'models/subway_congestion_model_enhanced.pkl'
        
        if not os.path.exists(model_path):
            print(f"âŒ ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {model_path}")
            raise FileNotFoundError(f"ëª¨ë¸ íŒŒì¼ ì—†ìŒ: {model_path}")
        
        with open(model_path, 'rb') as f:
            model_data = pickle.load(f)
            model = model_data['model']
            feature_names = model_data['feature_names']
        
        print(f"âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {model_path}")
        print(f"   - ëª¨ë¸ íƒ€ì…: {model_data.get('model_type', 'Unknown')}")
        print(f"   - í•™ìŠµ ì¼ì: {model_data.get('train_date', 'Unknown')}")
        print(f"   - í•„ìš”í•œ í”¼ì²˜ ìˆ˜: {len(feature_names)}")
        
        # 2. í”¼ì²˜ ë°ì´í„° ë¡œë“œ
        feature_path = 'data/processed/subway_features_balanced.csv'
        
        if os.path.exists(feature_path):
            print(f"\nğŸ“Š í”¼ì²˜ ë°ì´í„° ë¡œë”© ì¤‘...")
            df_features = pd.read_csv(feature_path, encoding='utf-8-sig')
            print(f"âœ… í”¼ì²˜ ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(df_features):,}ê°œ ë ˆì½”ë“œ")
            
            # 3. ì—­ ëª©ë¡ ìƒì„±
            if 'ì§€í•˜ì² ì—­' in df_features.columns and 'í˜¸ì„ ëª…' in df_features.columns:
                unique_stations = df_features[['ì§€í•˜ì² ì—­', 'í˜¸ì„ ëª…']].drop_duplicates()
                station_counts = df_features.groupby('ì§€í•˜ì² ì—­')['í˜¸ì„ ëª…'].nunique()
                is_transfer = station_counts > 1
                
                df_stations = unique_stations.copy()
                df_stations['í™˜ìŠ¹ì—­ì—¬ë¶€'] = df_stations['ì§€í•˜ì² ì—­'].map(is_transfer).fillna(False)
                
                print(f"âœ… ì—­ ì •ë³´ ìƒì„± ì™„ë£Œ: {len(df_stations)}ê°œ ì—­")
        else:
            print(f"âš ï¸  í”¼ì²˜ ë°ì´í„° ì—†ìŒ: {feature_path}")
            df_features = pd.DataFrame()
            df_stations = pd.DataFrame()
        
        print(f"\n" + "="*80)
        print("âœ… ì„œë²„ ì¤€ë¹„ ì™„ë£Œ!")
        print("="*80)
        print(f"ğŸ“ API ë¬¸ì„œ: http://localhost:8000/docs")
        print("="*80 + "\n")
        
    except Exception as e:
        print(f"\nâŒ ì„œë²„ ì‹œì‘ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        raise


# ============================================
# í”¼ì²˜ ì¤€ë¹„ í•¨ìˆ˜
# ============================================

def prepare_features(
    station_name: str,
    line_name: str,
    hour: int,
    day_of_week: int,
    month: int,
    is_holiday: bool
) -> Dict[str, float]:
    """ì˜ˆì¸¡ì„ ìœ„í•œ í”¼ì²˜ ì¤€ë¹„ (ê°•í™”ëœ í”¼ì²˜ í¬í•¨)"""
    
    current_year = datetime.now().year
    features = {}
    
    # 1. ì‹œê°„ ê´€ë ¨ í”¼ì²˜
    features['ì‹œê°„'] = float(hour)
    features['ì‹œê°„_sin'] = np.sin(2 * np.pi * hour / 24)
    features['ì‹œê°„_cos'] = np.cos(2 * np.pi * hour / 24)
    
    # ì‹œê°„ëŒ€ êµ¬ë¶„
    if 0 <= hour < 6:
        ì‹œê°„ëŒ€ = 0
    elif 6 <= hour < 9:
        ì‹œê°„ëŒ€ = 1
    elif 9 <= hour < 12:
        ì‹œê°„ëŒ€ = 2
    elif 12 <= hour < 14:
        ì‹œê°„ëŒ€ = 3
    elif 14 <= hour < 18:
        ì‹œê°„ëŒ€ = 4
    elif 18 <= hour < 21:
        ì‹œê°„ëŒ€ = 5
    else:
        ì‹œê°„ëŒ€ = 6
    
    features['ì‹œê°„ëŒ€êµ¬ë¶„_encoded'] = float(ì‹œê°„ëŒ€)
    
    # 2. ê°•í™”ëœ ì‹œê°„ í”¼ì²˜
    features['ì¶œê·¼ì‹œê°„ëŒ€'] = float(1 if 7 <= hour <= 9 else 0)
    features['í‡´ê·¼ì‹œê°„ëŒ€'] = float(1 if 18 <= hour <= 20 else 0)
    features['ì ì‹¬ì‹œê°„ëŒ€'] = float(1 if 12 <= hour <= 13 else 0)
    features['ì‹¬ì•¼ì‹œê°„ëŒ€'] = float(1 if 0 <= hour <= 5 else 0)
    features['ì €ë…ì‹œê°„ëŒ€'] = float(1 if 21 <= hour <= 23 else 0)
    
    # ëŸ¬ì‹œì•„ì›Œ ê°•ë„
    rush_intensity = 0.0
    if hour == 8:
        rush_intensity = 1.0
    elif hour in [7, 9]:
        rush_intensity = 0.7
    elif hour in [18, 19]:
        rush_intensity = 0.9
    elif hour == 20:
        rush_intensity = 0.6
    
    features['ëŸ¬ì‹œì•„ì›Œê°•ë„'] = rush_intensity
    
    # 3. ë‚ ì§œ ê´€ë ¨ í”¼ì²˜
    features['ìš”ì¼'] = float(day_of_week)
    features['ìš”ì¼_sin'] = np.sin(2 * np.pi * day_of_week / 7)
    features['ìš”ì¼_cos'] = np.cos(2 * np.pi * day_of_week / 7)
    
    features['ì›”'] = float(month)
    features['ì›”_sin'] = np.sin(2 * np.pi * month / 12)
    features['ì›”_cos'] = np.cos(2 * np.pi * month / 12)
    
    features['ì—°ë„'] = float(current_year)
    features['ë¶„ê¸°'] = float((month - 1) // 3 + 1)
    
    # 4. ì£¼ë§/ê³µíœ´ì¼ ì •ë³´
    is_weekend = day_of_week >= 5
    features['ì£¼ë§ì—¬ë¶€'] = float(1 if is_weekend else 0)
    features['ê³µíœ´ì¼ì—¬ë¶€'] = float(1 if is_holiday else 0)
    features['ê³µíœ´ì¼ì „ë‚ '] = 0.0
    features['ê³µíœ´ì¼ë‹¤ìŒë‚ '] = 0.0
    features['ì—°íœ´ì—¬ë¶€'] = float(1 if (is_weekend or is_holiday) else 0)
    
    # 5. ì—­/ë…¸ì„  ì •ë³´
    station_encoded = 0.0
    line_encoded = 0.0
    
    if df_features is not None and not df_features.empty:
        try:
            station_data = df_features[
                (df_features['ì§€í•˜ì² ì—­'] == station_name) &
                (df_features['í˜¸ì„ ëª…'] == line_name)
            ]
            
            if not station_data.empty:
                if 'ì§€í•˜ì² ì—­_encoded' in station_data.columns:
                    station_encoded = float(station_data['ì§€í•˜ì² ì—­_encoded'].iloc[0])
                
                if 'í˜¸ì„ ëª…_encoded' in station_data.columns:
                    line_encoded = float(station_data['í˜¸ì„ ëª…_encoded'].iloc[0])
                else:
                    line_encoding = {
                        '1í˜¸ì„ ': 0, '2í˜¸ì„ ': 1, '3í˜¸ì„ ': 2, '4í˜¸ì„ ': 3,
                        '5í˜¸ì„ ': 4, '6í˜¸ì„ ': 5, '7í˜¸ì„ ': 6, '8í˜¸ì„ ': 7, '9í˜¸ì„ ': 8,
                        'ê²½ì˜ì¤‘ì•™ì„ ': 9, 'ê³µí•­ì² ë„': 10, 'ê²½ì¶˜ì„ ': 11, 'ìˆ˜ì¸ë¶„ë‹¹ì„ ': 12,
                        'ì‹ ë¶„ë‹¹ì„ ': 13, 'ê²½ê°•ì„ ': 14, 'ì„œí•´ì„ ': 15, 'ì¸ì²œ1í˜¸ì„ ': 16,
                        'ì¸ì²œ2í˜¸ì„ ': 17, 'ìš°ì´ì‹ ì„¤ì„ ': 18, 'ì‹ ë¦¼ì„ ': 19
                    }
                    line_encoded = float(line_encoding.get(line_name, 0))
                
                if 'í™˜ìŠ¹ì—­ì—¬ë¶€' in station_data.columns:
                    features['í™˜ìŠ¹ì—­ì—¬ë¶€'] = float(station_data['í™˜ìŠ¹ì—­ì—¬ë¶€'].iloc[0])
                else:
                    station_lines = df_features[df_features['ì§€í•˜ì² ì—­'] == station_name]['í˜¸ì„ ëª…'].nunique()
                    features['í™˜ìŠ¹ì—­ì—¬ë¶€'] = float(1 if station_lines > 1 else 0)
        except Exception as e:
            print(f"âŒ ì¸ì½”ë”© ì˜¤ë¥˜: {e}")
    
    features['ì§€í•˜ì² ì—­_encoded'] = station_encoded
    features['í˜¸ì„ ëª…_encoded'] = line_encoded
    
    # 6. ì—­ ì¹´í…Œê³ ë¦¬ í”¼ì²˜
    station_category = STATION_CATEGORIES.get(station_name, DEFAULT_CATEGORY)
    
    features['ì—­_ì—…ë¬´ì§€êµ¬'] = float(station_category['ì—…ë¬´ì§€êµ¬'])
    features['ì—­_ìƒì—…ì§€êµ¬'] = float(station_category['ìƒì—…ì§€êµ¬'])
    features['ì—­_í™˜ìŠ¹ì—­ë“±ê¸‰'] = float(station_category['í™˜ìŠ¹ì—­ë“±ê¸‰'])
    features['ì—­_ëŒ€í•™ê°€'] = float(station_category['ëŒ€í•™ê°€'])
    features['ì—­_ì£¼ê±°ì§€ì—­'] = float(station_category['ì£¼ê±°ì§€ì—­'])
    features['ì—­_ê·¸ë£¹'] = float(station_category['ì—­_ê·¸ë£¹'])
    
    # 7. ê¸°ë³¸ ìƒí˜¸ì‘ìš© í”¼ì²˜
    features['time_dow_interaction'] = ì‹œê°„ëŒ€ * 10 + day_of_week
    features['station_time_interaction'] = station_encoded * 10 + ì‹œê°„ëŒ€
    
    # 8. ê°•í™”ëœ ìƒí˜¸ì‘ìš© í”¼ì²˜
    features['business_rush_interaction'] = features['ì—­_ì—…ë¬´ì§€êµ¬'] * rush_intensity * 10
    features['transfer_rush_interaction'] = features['ì—­_í™˜ìŠ¹ì—­ë“±ê¸‰'] * rush_intensity * 10
    features['university_morning_interaction'] = features['ì—­_ëŒ€í•™ê°€'] * features['ì¶œê·¼ì‹œê°„ëŒ€']
    
    # í‰ì¼/ì£¼ë§ Ã— ì—­ ì¹´í…Œê³ ë¦¬
    features['business_weekday'] = features['ì—­_ì—…ë¬´ì§€êµ¬'] * (1 - features['ì£¼ë§ì—¬ë¶€'])
    features['commercial_weekend'] = features['ì—­_ìƒì—…ì§€êµ¬'] * features['ì£¼ë§ì—¬ë¶€']
    
    # 9. 3-way ìƒí˜¸ì‘ìš©
    features['group_time_dow'] = (features['ì—­_ê·¸ë£¹'] * 100 + 
                                   ì‹œê°„ëŒ€ * 10 + 
                                   day_of_week)
    
    features['transfer_rush_weekday'] = (features['ì—­_í™˜ìŠ¹ì—­ë“±ê¸‰'] * 
                                          features['ì¶œê·¼ì‹œê°„ëŒ€'] * 
                                          (1 - features['ì£¼ë§ì—¬ë¶€']))
    
    # 10. ëˆ„ë½ëœ í”¼ì²˜ 0ìœ¼ë¡œ ì±„ìš°ê¸°
    for feature_name in feature_names:
        if feature_name not in features:
            features[feature_name] = 0.0
    
    return features


# ============================================
# API ì—”ë“œí¬ì¸íŠ¸
# ============================================

@app.get("/")
async def root():
    """ë£¨íŠ¸ ì—”ë“œí¬ì¸íŠ¸"""
    return {
        "message": "ì§€í•˜ì²  í˜¼ì¡ë„ ì˜ˆì¸¡ API",
        "version": "1.0.0",
        "model": "enhanced (ê°•í™”ëœ í”¼ì²˜)",
        "docs": "/docs"
    }


@app.get("/health")
async def health_check():
    """í—¬ìŠ¤ì²´í¬"""
    return {
        "status": "healthy",
        "model_loaded": model is not None,
        "features_count": len(feature_names) if feature_names else 0,
        "data_loaded": df_features is not None and not df_features.empty,
        "timestamp": datetime.now().isoformat()
    }


@app.get("/stations")
async def get_stations(
    line_name: Optional[str] = None,
    search: Optional[str] = None
):
    """ì—­ ëª©ë¡ ì¡°íšŒ"""
    if df_stations is None or df_stations.empty:
        raise HTTPException(status_code=503, detail="ì—­ ì •ë³´ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
    
    result = df_stations.copy()
    
    if line_name:
        result = result[result['í˜¸ì„ ëª…'] == line_name]
    
    if search:
        result = result[result['ì§€í•˜ì² ì—­'].str.contains(search, case=False, na=False)]
    
    stations = []
    for _, row in result.head(100).iterrows():
        stations.append({
            "name": row['ì§€í•˜ì² ì—­'],
            "line": row['í˜¸ì„ ëª…'],
            "is_transfer": bool(row.get('í™˜ìŠ¹ì—­ì—¬ë¶€', False))
        })
    
    return {
        "success": True,
        "total": len(result),
        "stations": stations
    }


@app.get("/lines")
async def get_lines():
    """í˜¸ì„  ëª©ë¡ ì¡°íšŒ"""
    if df_stations is None or df_stations.empty:
        lines = ["1í˜¸ì„ ", "2í˜¸ì„ ", "3í˜¸ì„ ", "4í˜¸ì„ ", "5í˜¸ì„ ", "6í˜¸ì„ ", "7í˜¸ì„ ", "8í˜¸ì„ ", "9í˜¸ì„ "]
    else:
        lines = sorted(df_stations['í˜¸ì„ ëª…'].unique().tolist())
    
    return {
        "success": True,
        "total": len(lines),
        "lines": lines
    }


@app.post("/predict", response_model=PredictionResponse)
async def predict_congestion(request: PredictionRequest):
    """í˜¼ì¡ë„ ì˜ˆì¸¡"""
    
    if model is None:
        raise HTTPException(status_code=503, detail="ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
    
    try:
        month = request.month or datetime.now().month
        hour = request.hour
        
        # í”¼ì²˜ ì¤€ë¹„
        features = prepare_features(
            station_name=request.station_name,
            line_name=request.line_name,
            hour=hour,
            day_of_week=request.day_of_week,
            month=month,
            is_holiday=request.is_holiday
        )
        
        # ëª¨ë¸ ì…ë ¥ ì¤€ë¹„
        feature_values = [features[name] for name in feature_names]
        X = np.array([feature_values])
        
        # ì˜ˆì¸¡
        prediction = model.predict(X)[0]
        probabilities = model.predict_proba(X)[0]
        
        # ğŸ”¥ ë§¤ìš° ê³µê²©ì ì¸ ë¶„ë¥˜ ë¡œì§: ëŸ¬ì‹œì•„ì›ŒëŠ” ë¬´ì¡°ê±´ í˜¼ì¡ ì´ìƒ
        max_prob_class = int(np.argmax(probabilities))
        
        # ê¸°ë³¸ ì˜ˆì¸¡
        adjusted_prediction = max_prob_class
        
        # ğŸ”¥ğŸ”¥ ëŸ¬ì‹œì•„ì›Œ ê°•ì œ ì¡°ì • (7-9ì‹œ, 18-20ì‹œ)
        if 7 <= hour <= 9 or 18 <= hour <= 20:
            # ëŸ¬ì‹œì•„ì›Œì—ëŠ” ìµœì†Œ "í˜¼ì¡" ë³´ì¥
            if adjusted_prediction < 2:
                adjusted_prediction = 2  # ë¬´ì¡°ê±´ í˜¼ì¡ ì´ìƒ
            
            # ì¶”ê°€ ìƒí–¥ ì¡°ê±´: í™•ë¥  í•©ì‚°
            í˜¼ì¡_ì´ìƒ_í™•ë¥  = probabilities[2] + probabilities[3]
            
            if í˜¼ì¡_ì´ìƒ_í™•ë¥  > 0.05:  # 5%ë§Œ ë„˜ì–´ë„ í˜¼ì¡
                adjusted_prediction = 2
            
            if probabilities[3] > 0.02:  # ë§¤ìš°í˜¼ì¡ í™•ë¥  2% ì´ìƒ
                adjusted_prediction = 3
            
            # ğŸ”¥ ì—­ íŠ¹ì„± ì¶”ê°€ ìƒí–¥
            station_category = STATION_CATEGORIES.get(request.station_name, DEFAULT_CATEGORY)
            
            # í™˜ìŠ¹ì—­ì€ ë” ê³µê²©ì ìœ¼ë¡œ
            if station_category['í™˜ìŠ¹ì—­ë“±ê¸‰'] >= 2:
                if probabilities[3] > 0.01:  # 1%ë§Œ ë„˜ì–´ë„ ë§¤ìš°í˜¼ì¡
                    adjusted_prediction = 3
                else:
                    adjusted_prediction = max(adjusted_prediction, 2)  # ìµœì†Œ í˜¼ì¡
            
            # ì—…ë¬´ì§€êµ¬ + ì¶œê·¼ì‹œê°„ (7-9ì‹œ)
            if station_category['ì—…ë¬´ì§€êµ¬'] == 1 and 7 <= hour <= 9:
                if probabilities[3] > 0.015:
                    adjusted_prediction = 3
                else:
                    adjusted_prediction = max(adjusted_prediction, 2)
            
            # ìƒì—…ì§€êµ¬ + í‡´ê·¼ì‹œê°„ (18-20ì‹œ)
            if station_category['ìƒì—…ì§€êµ¬'] == 1 and 18 <= hour <= 20:
                adjusted_prediction = max(adjusted_prediction, 2)
        
        # ì ì‹¬ ì‹œê°„ëŒ€ (12-13ì‹œ): ìµœì†Œ ë³´í†µ
        elif 12 <= hour <= 13:
            if adjusted_prediction == 0:
                adjusted_prediction = 1
        
        # ì €ë… ì‹œê°„ëŒ€ (21-22ì‹œ): ìµœì†Œ ë³´í†µ
        elif 21 <= hour <= 22:
            if adjusted_prediction == 0 and probabilities[1] > 0.03:
                adjusted_prediction = 1
        
        # ì˜¤ì „/ì˜¤í›„ (10-11ì‹œ, 14-17ì‹œ): ê°€ë²¼ìš´ ìƒí–¥
        elif (10 <= hour <= 11) or (14 <= hour <= 17):
            if adjusted_prediction == 0 and probabilities[1] + probabilities[2] > 0.08:
                adjusted_prediction = 1
        
        # íŠ¹ìˆ˜ ì¼€ì´ìŠ¤ í•˜í–¥ ì¡°ì • (ìµœì†Œí•œë§Œ)
        # ì‹¬ì•¼ ì‹œê°„(0-5ì‹œ)ì€ ìµœëŒ€ "ë³´í†µ"
        if hour <= 5:
            adjusted_prediction = min(adjusted_prediction, 1)
        
        # ì£¼ë§ ì‹¬ì•¼(23ì‹œ)ëŠ” ìµœëŒ€ "í˜¼ì¡"
        if request.day_of_week >= 5 and hour >= 23:
            adjusted_prediction = min(adjusted_prediction, 2)
        
        final_prediction = adjusted_prediction
        
        # ê²°ê³¼ í¬ë§·
        prediction_result = {
            "congestion_level": int(final_prediction),
            "congestion_label": CONGESTION_LEVEL_MAP[int(final_prediction)],
            "probability": {
                "ì—¬ìœ ": float(probabilities[0]),
                "ë³´í†µ": float(probabilities[1]),
                "í˜¼ì¡": float(probabilities[2]),
                "ë§¤ìš°í˜¼ì¡": float(probabilities[3])
            }
        }
        
        # ì…ë ¥ ì •ë³´
        input_info = {
            "station_name": request.station_name,
            "line_name": request.line_name,
            "hour": request.hour,
            "day_of_week": request.day_of_week,
            "day_name": DAY_NAME_MAP[request.day_of_week],
            "month": month,
            "is_holiday": request.is_holiday,
            "is_weekend": request.day_of_week >= 5
        }
        
        # ì¶”ì²œ ë©”ì‹œì§€
        level = int(final_prediction)
        is_rush_hour = hour in [7, 8, 9, 18, 19, 20]
        
        if level == 0:
            recommendation = "ì—¬ìœ ë¡œìš´ ì‹œê°„ëŒ€ì…ë‹ˆë‹¤. í¸í•˜ê²Œ ì´ìš©í•˜ì„¸ìš”."
        elif level == 1:
            recommendation = "ë³´í†µ ìˆ˜ì¤€ì˜ í˜¼ì¡ë„ì…ë‹ˆë‹¤."
        elif level == 2:
            if is_rush_hour:
                recommendation = "í˜¼ì¡í•œ ì‹œê°„ëŒ€ì…ë‹ˆë‹¤. ê°€ëŠ¥í•˜ë©´ 30ë¶„ ì „í›„ ì´ìš©ì„ ê¶Œì¥í•©ë‹ˆë‹¤."
            else:
                recommendation = "ë‹¤ì†Œ í˜¼ì¡í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
        else:
            if is_rush_hour:
                recommendation = "ë§¤ìš° í˜¼ì¡í•œ ì‹œê°„ëŒ€ì…ë‹ˆë‹¤. ë‹¤ìŒ ì‹œê°„ëŒ€ ì´ìš©ì„ ì ê·¹ ê¶Œì¥í•©ë‹ˆë‹¤."
            else:
                recommendation = "ë§¤ìš° í˜¼ì¡í•©ë‹ˆë‹¤. ì‹œê°„ ì¡°ì •ì„ ê¶Œì¥í•©ë‹ˆë‹¤."
        
        return PredictionResponse(
            success=True,
            prediction=prediction_result,
            input=input_info,
            recommendation=recommendation,
            timestamp=datetime.now().isoformat()
        )
        
    except Exception as e:
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"ì˜ˆì¸¡ ì¤‘ ì˜¤ë¥˜: {str(e)}")


@app.post("/predict/hourly")
async def predict_hourly(
    station_name: str,
    line_name: str,
    day_of_week: int,
    month: Optional[int] = None,
    is_holiday: Optional[bool] = False
):
    """ì‹œê°„ëŒ€ë³„ í˜¼ì¡ë„ ì˜ˆì¸¡"""
    
    if model is None:
        raise HTTPException(status_code=503, detail="ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
    
    month = month or datetime.now().month
    predictions = []
    
    for hour in range(24):
        try:
            features = prepare_features(
                station_name=station_name,
                line_name=line_name,
                hour=hour,
                day_of_week=day_of_week,
                month=month,
                is_holiday=is_holiday
            )
            
            feature_values = [features[name] for name in feature_names]
            X = np.array([feature_values])
            
            prediction = model.predict(X)[0]
            probabilities = model.predict_proba(X)[0]
            
            # ğŸ”¥ ë™ì¼í•œ ê³µê²©ì  ë¡œì§ ì ìš©
            max_prob_class = int(np.argmax(probabilities))
            adjusted_prediction = max_prob_class
            
            # ğŸ”¥ğŸ”¥ ëŸ¬ì‹œì•„ì›Œ ê°•ì œ ì¡°ì • (7-9ì‹œ, 18-20ì‹œ)
            if 7 <= hour <= 9 or 18 <= hour <= 20:
                # ëŸ¬ì‹œì•„ì›Œì—ëŠ” ìµœì†Œ "í˜¼ì¡" ë³´ì¥
                if adjusted_prediction < 2:
                    adjusted_prediction = 2
                
                í˜¼ì¡_ì´ìƒ_í™•ë¥  = probabilities[2] + probabilities[3]
                
                if í˜¼ì¡_ì´ìƒ_í™•ë¥  > 0.05:
                    adjusted_prediction = 2
                
                if probabilities[3] > 0.02:
                    adjusted_prediction = 3
                
                # ì—­ íŠ¹ì„± ì¶”ê°€ ìƒí–¥
                station_category = STATION_CATEGORIES.get(station_name, DEFAULT_CATEGORY)
                
                if station_category['í™˜ìŠ¹ì—­ë“±ê¸‰'] >= 2:
                    if probabilities[3] > 0.01:
                        adjusted_prediction = 3
                    else:
                        adjusted_prediction = max(adjusted_prediction, 2)
                
                if station_category['ì—…ë¬´ì§€êµ¬'] == 1 and 7 <= hour <= 9:
                    if probabilities[3] > 0.015:
                        adjusted_prediction = 3
                    else:
                        adjusted_prediction = max(adjusted_prediction, 2)
                
                if station_category['ìƒì—…ì§€êµ¬'] == 1 and 18 <= hour <= 20:
                    adjusted_prediction = max(adjusted_prediction, 2)
            
            # ì ì‹¬ ì‹œê°„ëŒ€ (12-13ì‹œ): ìµœì†Œ ë³´í†µ
            elif 12 <= hour <= 13:
                if adjusted_prediction == 0:
                    adjusted_prediction = 1
            
            # ì €ë… ì‹œê°„ëŒ€ (21-22ì‹œ): ìµœì†Œ ë³´í†µ
            elif 21 <= hour <= 22:
                if adjusted_prediction == 0 and probabilities[1] > 0.03:
                    adjusted_prediction = 1
            
            # ì˜¤ì „/ì˜¤í›„ (10-11ì‹œ, 14-17ì‹œ): ê°€ë²¼ìš´ ìƒí–¥
            elif (10 <= hour <= 11) or (14 <= hour <= 17):
                if adjusted_prediction == 0 and probabilities[1] + probabilities[2] > 0.08:
                    adjusted_prediction = 1
            
            # íŠ¹ìˆ˜ ì¼€ì´ìŠ¤ í•˜í–¥ ì¡°ì •
            if hour <= 5:
                adjusted_prediction = min(adjusted_prediction, 1)
            
            if day_of_week >= 5 and hour >= 23:
                adjusted_prediction = min(adjusted_prediction, 2)
            
            final_prediction = adjusted_prediction
            
            predictions.append({
                "hour": hour,
                "time": f"{hour:02d}:00",
                "congestion_level": int(final_prediction),
                "congestion_label": CONGESTION_LEVEL_MAP[int(final_prediction)],
                "probability": float(probabilities[int(final_prediction)])
            })
            
        except Exception as e:
            print(f"ì‹œê°„ {hour} ì˜ˆì¸¡ ì‹¤íŒ¨: {e}")
            continue
    
    # ìš”ì•½ í†µê³„
    if predictions:
        levels = [p['congestion_level'] for p in predictions]
        most_congested = [p['hour'] for p in predictions if p['congestion_level'] >= 2]
        least_congested = [p['hour'] for p in predictions if p['congestion_level'] == 0]
        
        summary = {
            "most_congested_hours": most_congested[:5],
            "least_congested_hours": least_congested[:5],
            "average_congestion": round(sum(levels) / len(levels), 2)
        }
    else:
        summary = {}
    
    return {
        "success": True,
        "station_name": station_name,
        "line_name": line_name,
        "day_of_week": day_of_week,
        "day_name": DAY_NAME_MAP[day_of_week],
        "predictions": predictions,
        "summary": summary,
        "timestamp": datetime.now().isoformat()
    }


@app.get("/model/info")
async def get_model_info():
    """ëª¨ë¸ ì •ë³´ ì¡°íšŒ"""
    
    if model is None:
        raise HTTPException(status_code=503, detail="ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
    
    try:
        with open('models/subway_congestion_model_enhanced.pkl', 'rb') as f:
            model_data = pickle.load(f)
        
        return {
            "success": True,
            "model_info": {
                "model_type": model_data.get('model_type', 'Unknown'),
                "train_date": model_data.get('train_date', 'Unknown'),
                "feature_count": len(feature_names),
                "features": feature_names[:10],
                "note": model_data.get('note', '')
            },
            "timestamp": datetime.now().isoformat()
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ëª¨ë¸ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")


if __name__ == "__main__":
    import uvicorn
    
    print("\n" + "="*80)
    print("ğŸš‡ ì§€í•˜ì²  í˜¼ì¡ë„ ì˜ˆì¸¡ API ì„œë²„")
    print("="*80)
    print("ğŸ“ ì„œë²„ ì£¼ì†Œ: http://localhost:8000")
    print("ğŸ“š API ë¬¸ì„œ: http://localhost:8000/docs")
    print("="*80 + "\n")
    
    uvicorn.run(app, host="0.0.0.0", port=8000)